# -*- coding: utf-8 -*-
"""Copy of  machine learning3 & project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oSQsn1gt6QptNa1mEZ-tLnRF0MYoyqkn

# Decision Tree learvern
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import linear_model

df = pd.read_csv('/content/Social_Network_Ads (1).csv')

df

X=df.iloc[:,[2,3]]

Y=df.iloc[:,4]

from sklearn.model_selection import train_test_split
train_test_split

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.25,random_state=0)

len(X_train)

len(X_test)

# from sklearn.preprocessing import StandardScaler

# sc= StandardScaler()

# X_train=sc.fit_transform(X_train)

# X_test=sc.fit_transform(X_test)

from sklearn.tree import DecisionTreeClassifier

dtcf=DecisionTreeClassifier(criterion="gini",splitter="random",random_state=0)

dtcf.fit(X_train,y_train)

Y_pred=dtcf.predict(X_test)

Y_pred

y_test

dtcf.score(X_test,y_test)



"""# Desion Tree from youtube"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import linear_model

df = pd.read_csv('/content/salaries.csv')

df

input=df.drop('salary_more_then_100k',axis=1)
input

target=df['salary_more_then_100k']
target

from sklearn.preprocessing import LabelEncoder

le_company=LabelEncoder()
le_job=LabelEncoder()
le_degree=LabelEncoder()

input['company_n']=le_company.fit_transform(input['company'])
input['job_n']=le_company.fit_transform(input['job'])
input['degree_n']=le_company.fit_transform(input['degree'])

input

input_n=input.drop(['company','job','degree'],axis=1)

input_n

from sklearn.model_selection import train_test_split
train_test_split

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(input_n,target, test_size=0.2,random_state=0)

len(X_train)

len(X_test)



from sklearn.tree import DecisionTreeClassifier

dtcf=DecisionTreeClassifier(criterion="gini",splitter="random",random_state=0)

dtcf.fit(X_train,y_train)



Y_pred=dtcf.predict(X_test)

Y_pred

dtcf.score(input_n,target)

"""# Dicision tree practice 2"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import linear_model

df = pd.read_csv('/content/golf-dataset.csv')

df

inputs=df.drop('Play Golf',axis=1)
inputs

target=df['Play Golf']
target

from sklearn.preprocessing import LabelEncoder

le_Outlook= LabelEncoder()
le_Temp =LabelEncoder()
le_Humidity =LabelEncoder()
le_Windy =LabelEncoder()

inputs['Outlook_n']=le_Outlook.fit_transform(inputs['Outlook'])
inputs['Temp_n']=le_Temp.fit_transform(inputs['Temp'])
inputs['Humidity_n']=le_Humidity.fit_transform(inputs['Humidity'])
inputs['Windy_n']=le_Windy.fit_transform(inputs['Windy'])

inputs

inputs_n=inputs.drop(['Outlook','Temp','Humidity','Windy'],axis=1)

inputs_n

from sklearn.model_selection import train_test_split
train_test_split

# prompt: train_test_split

X_train, X_test, y_train, y_test = train_test_split(inputs_n,target, test_size=0.3,random_state=0)

len(X_train)

len(X_test)

from sklearn.tree import DecisionTreeClassifier

dtcf=DecisionTreeClassifier(criterion='gini',splitter='random')

dtcf.fit(inputs_n,target)

Y_pred=dtcf.predict(X_test)

Y_pred

y_test

dtcf.score(inputs_n,target)



"""# Support vector Machine"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import linear_model

df = pd.read_csv('/content/Social_Network_Ads (1).csv')

df

X=df.iloc[:,[2,3]]

Y=df.iloc[:,4]

from sklearn.model_selection import train_test_split
train_test_split

# prompt: train_test_split

X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.25,random_state=0)

len(X_train)

len(X_test)

from sklearn.naive_bayes import GaussianNB

gnb=GaussianNB()

gnb.fit(X_train,y_train)

y_pred=gnb.predict(X_test)

y_pred

y_test

from sklearn.metrics import accuracy_score,confusion_matrix

print("Accuracy :", accuracy_score(y_test,y_pred).round(2))

cf=confusion_matrix(y_test,y_pred)

cf

gnb.score(X_train,y_train).round(2)



"""# Support Vector Machine"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import linear_model

from sklearn.datasets import load_iris

iris=load_iris()

iris.feature_names

iris.target_names

df=pd.DataFrame(iris.data,columns=iris.feature_names)

df=df.drop(['target','flower_name'],axis=1)

df

df['target']=iris.target

df

df[df.target==2].head()

df['flower_name']=df.target.apply(lambda x:iris.target_names[x])

df.head()

df0=df[:50]
df1=df[50:100]
df1=df[100:150]

plt.xlabel('sepal length ')
plt.xlabel('sepal width ')
plt.scatter(df0['sepal length (cm)'],df0['sepal width (cm)'],color='green',marker='*')
plt.scatter(df1['sepal length (cm)'],df1['sepal width (cm)'],color='red',marker='+')

X=df.iloc[:,0:4]

X

Y=df.iloc[:,[5]]

Y

from sklearn.model_selection import train_test_split
train_test_split

# prompt: train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)

len(X_test)

from sklearn.svm import SVC

svc=SVC()

svc.fit(X_train,y_train)

y_pred=gnb.predict(X_test)

y_pred

y_test.values

X_test

y_pred=gnb.predict([[5.8,2.8,5.1,2.4]])

y_pred

svc.score(X_test,y_test)



"""# Naive bayes classifier"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import linear_model

df = pd.read_csv('/content/Social_Network_Ads (1).csv')

X=df.iloc[:,[2,3]].values

Y=df.iloc[:,4].values

from sklearn.model_selection import train_test_split
train_test_split

# prompt: train_test_split

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.25,random_state=0)

len(X_train)

len(X_test)

from sklearn.preprocessing import StandardScaler

sc= StandardScaler()

X_train=sc.fit_transform(X_train)

X_test=sc.fit_transform(X_test)

from sklearn.svm import SVC

svc=SVC(random_state=0)

svc.fit(X_train,y_train)

y_pred=svc.predict(X_test)

y_pred

y_test

from sklearn.metrics import accuracy_score,confusion_matrix

print("Accuracy :", accuracy_score(y_test,y_pred))

cf=confusion_matrix(y_test,y_pred)

cf

svc.score(X_train,y_train)



"""# Naive bayes classifire"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import linear_model

from sklearn.datasets import load_iris

X,y=load_iris(return_X_y=True)

X

y

len(X)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25,random_state=0)

from sklearn.preprocessing import StandardScaler

sc= StandardScaler()

X_train=sc.fit_transform(X_train)

X_test=sc.fit_transform(X_test)

from sklearn.naive_bayes import GaussianNB

gnb=GaussianNB()

gnb.fit(X_train,y_train)

y_pred=gnb.predict(X_test)

y_pred

y_test

from sklearn.metrics import accuracy_score,confusion_matrix

print("Accuracy :", accuracy_score(y_test,y_pred).round(2))

gnb.score(X_train,y_train).round(2)

plt.scatter(X_test[:,0],X_test[:,1],c=y_pred)

plt.scatter(X_test[:,0],X_test[:,1],c=y_test)



"""# Unsupervised Learning ------------------- K-Mean Algorithm"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import linear_model

df = pd.read_csv('/content/Mall_Customers.csv')

df.head()

X=df.iloc[:,[3,4]].values

X.shape

from sklearn.preprocessing import StandardScaler

sc= StandardScaler()

X=sc.fit_transform(X)
X

from sklearn.cluster import KMeans

#k --- now be find the no. of clustring
wcss=[]
for i in range(1,11):
  kmeans = KMeans(n_clusters=i,init='k-means++',random_state=0)
  kmeans.fit(X)
  wcss.append(kmeans.inertia_)

plt.plot(range(1,11),wcss)
plt.title("elbow method")
plt.xlabel("number of cluster")
plt.ylabel("wcss")

#K=5

kmeans=KMeans(n_clusters=5,init='k-means++',random_state=0)

kmeans.fit(X)

y_clustar=kmeans.predict(X)

y_clustar

x1=X[:,0]
x2=X[:,1]

plt.scatter(x1,x2,c=y_clustar)

"""# The Loan prediction project:\

---


"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import linear_model

df = pd.read_csv('/content/train.csv')

df.head()

df.info()

df.isna().sum()

df['Gender'].value_counts()

df.Gender=df.Gender.fillna('Male')

df['Self_Employed'].value_counts()

df['Dependents'].value_counts()

df.Self_Employed=df.Self_Employed.fillna('No')

df.Gender=df.Gender.fillna('Male')

df['Dependents'].value_counts()

df.Married=df.Married.fillna('Yes')

df['Married'].value_counts()

df['Loan_Amount_Term'].value_counts()

df.Loan_Amount_Term=df.Loan_Amount_Term.fillna(360.0)

df['Credit_History'].value_counts()

df.Credit_History=df.Credit_History.fillna(1.0)

df['LoanAmount'].value_counts()

df.LoanAmount=df.LoanAmount.fillna(120)

df.isna().sum()

X=df.iloc[:,1:12].values
X

y=df.iloc[:,12]
y

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25,random_state=0)

len(X_train)

len(X_test)

from sklearn.preprocessing import LabelEncoder

labelEncoder=LabelEncoder()

for i in range(0,5):
  X_train[:,i]=labelEncoder.fit_transform(X_train[:,i])

X_train[:,10]=labelEncoder.fit_transform(X_train[:,10])

labelEncoder_y=LabelEncoder()

y_train=labelEncoder_y.fit_transform(y_train)

labelEncoder_xt=LabelEncoder()
for i in range(0,5):
  X_test[:,i]=labelEncoder_xt.fit_transform(X_test[:,i])
X_test[:,10]=labelEncoder_xt.fit_transform(X_test[:,10])

labelEncoder_yt=LabelEncoder()
y_test=labelEncoder_yt.fit_transform(y_test)

# from sklearn.preprocessing import StandardScaler

# sc= StandardScaler()

# X_train=sc.fit_transform(X_train)

# X_test=sc.fit_transform(X_test)

#PCA
from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_train=pca.fit_transform(X_train)
X_test=pca.fit_transform(X_test)

# classification
# logistic regration
# SVC
# neighst neaver
from sklearn.linear_model import LogisticRegression

model=LogisticRegression()

model.fit(X_train, y_train)

y_predict=model.predict(X_test)
y_predict

y_test

from sklearn.metrics import accuracy_score,confusion_matrix

# prompt: accuracy_score

print("Accuracy :", accuracy_score(y_test,y_predict))

# prompt: confusion_matrix

from sklearn.metrics import confusion_matrix

cf=confusion_matrix(y_test,y_predict)
print(cf)

model.score(X_train,y_train)

plt.scatter(X_test[:,0],y_test,c=y_test)

plt.scatter(X_test[:,0],y_predict,c=y_predict)

#SVC
from sklearn.svm import SVC

svc_r=SVC(random_state=0)
svc_l=SVC(random_state=0)

svc_r.fit(X_train,y_train)
svc_l.fit(X_train,y_train)

y_pred_r=svc_r.predict(X_test)
y_pred_l=svc_l.predict(X_test)

from sklearn.metrics import accuracy_score,confusion_matrix

print("Accuracy :", accuracy_score(y_test,y_pred_r))

print("Accuracy :", accuracy_score(y_test,y_pred_l))



#kNN
from sklearn.neighbors import KNeighborsClassifier

knn=KNeighborsClassifier(n_neighbors= 5)

knn.fit(X_train,y_train)

y_pred=knn.predict(X_test)
y_pred

from sklearn.metrics import accuracy_score,confusion_matrix
print("Accuracy :", accuracy_score(y_test,y_pred))

# prompt: confusion_matrix

from sklearn.metrics import confusion_matrix

cf=confusion_matrix(y_test,y_pred)
print(cf)

knn.score(X_test,y_test)

plt.scatter(X_test[:,0],y_test,c=y_test)

plt.scatter(X_test[:,0],y_pred,c=y_pred)

"""# Car price prediction  Project"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import linear_model
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

df = pd.read_csv('/content/quikr_car.csv')
df.head()

df.info()

df['year'].unique()

df=df[df['year'].str.isnumeric()]

df['year']=df['year'].astype(int)
df['year']

df=df[df['Price']!='Ask For Price']

df['Price']=df['Price'].str.replace(',','').astype(int)

df.info()

df['kms_driven'] = df['kms_driven'].str.replace(' kms', '')

df['kms_driven']=df['kms_driven'].str.replace(',', '')

df=df[df['kms_driven'].str.isnumeric()]

df['kms_driven']=df['kms_driven'].astype(int)

df.info()

df['name']=df['name'].str.split(' ').str.slice(0,3).str.join(' ')

df['name']

df.info()

df=df[~df['fuel_type'].isna()]

df.info()

df=df[df['Price']<6e6].reset_index(drop=True)

df.info()

df.to_csv('Car_data')

#from sklearn.preprocessing import LabelEncoder













"""# Laptop price predictor"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import linear_model
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

df = pd.read_csv('/content/laptop_data.csv')
df.head()

df=df.drop('Unnamed: 0',axis=1)

df.head()

df.info()

column=df.columns

for i in column:
  uni=df[i].unique()
  print(uni)
  print('************************************************************')

for i in column:
  val=df[i].value_counts()
  print(val)
  print('************************************************************')

for i in column:
  val=df[i].isna().sum()
  print(val)
  print('************************************************************')

df['Ram']=df['Ram'].str.replace('GB','')

df['Weight']=df['Weight'].str.replace('kg','')

df['Weight']=df['Weight'].astype(float)

df.info()

df.head()

sns.distplot(df['Price'])

# most sell company
df['Company'].value_counts().plot(kind='bar')

sns.barplot(x=df['Company'],y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

df['TypeName'].value_counts().plot(kind='bar')

sns.barplot(x=df['TypeName'],y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

df.head(1)

sns.distplot(df['Inches'])

# prompt: sns.scatterplot()

sns.scatterplot(x = df['Inches'], y = df['Price'])
plt.show()

df.head(1)

df['ScreenResolution'].value_counts()

df['Touchscreen']=df['ScreenResolution'].apply(lambda x:1 if 'Touchscreen' in x else 0 )

df['Touchscreen'].value_counts().plot(kind='bar')

sns.barplot(x=df['Touchscreen'],y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

df['IPS']=df['ScreenResolution'].apply(lambda x:1 if 'IPS' in x else 0 )

df['IPS'].value_counts().plot(kind='bar')

sns.barplot(x=df['IPS'],y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

new = df['ScreenResolution'].str.split('x',n=1,expand=True)
new

df['X_res'] = new[0]
df['Y_res'] = new[1]

df['X_res']=df['X_res'].str.replace(r'\D', '')
df['X_res']

df['X_res']=df['X_res'].astype(int)
df['Y_res']=df['Y_res'].astype(int)

df.info()

df.sample(2)

df.corr()['Price']

df['ppi'] = (((df['X_res']**2) + (df['Y_res']**2))**0.5/df['Inches']).astype('float')

df.corr()['Price']

df.head(1)

df.drop(columns=['ScreenResolution'],inplace=True)

df.drop(columns=['Inches','X_res','Y_res'],inplace=True)

df.head(1)

df['Cpu'].value_counts()

# Both are true
# df['Cpu Name'] = df['Cpu'].str.split(' ').str.slice(0,3).str.join(' ')

df['Cpu Name'] = df['Cpu'].apply(lambda x:" ".join(x.split()[0:3]))

df['Cpu Name']

df['Cpu Name'].value_counts()

def processer(text):

  if text=='Intel Core i7' or text=='Intel Core i5' or text=='Intel Core i3':

    return text

  elif text.split()[0]=='Intel':
    return 'Other Intel Processor'
  else:
    return 'AMD processer'

df['Cpu barnd']=df['Cpu Name'].apply(processer)

df['Cpu barnd']

df['Cpu barnd'].value_counts().plot(kind='bar')

sns.barplot(x=df['Cpu barnd'],y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

df.drop(columns=['Cpu','Cpu Name'],inplace=True)

df.head(2)

df['Ram'].value_counts().plot(kind='bar')

sns.barplot(x=df['Ram'],y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

df.Memory.value_counts()

df['Memory'] = df['Memory'].astype(str).replace('\.0', '', regex=True)
df["Memory"] = df["Memory"].str.replace('GB', '')
df["Memory"] = df["Memory"].str.replace('TB', '000')
new = df["Memory"].str.split("+", n = 1, expand = True)

df["first"]= new[0]
df["first"]=df["first"].str.strip()

df["second"]= new[1]

df["Layer1HDD"] = df["first"].apply(lambda x: 1 if "HDD" in x else 0)
df["Layer1SSD"] = df["first"].apply(lambda x: 1 if "SSD" in x else 0)
df["Layer1Hybrid"] = df["first"].apply(lambda x: 1 if "Hybrid" in x else 0)
df["Layer1Flash_Storage"] = df["first"].apply(lambda x: 1 if "Flash Storage" in x else 0)

df['first'] = df['first'].str.replace(r'\D', '')

df["second"].fillna("0", inplace = True)

df["Layer2HDD"] = df["second"].apply(lambda x: 1 if "HDD" in x else 0)
df["Layer2SSD"] = df["second"].apply(lambda x: 1 if "SSD" in x else 0)
df["Layer2Hybrid"] = df["second"].apply(lambda x: 1 if "Hybrid" in x else 0)
df["Layer2Flash_Storage"] = df["second"].apply(lambda x: 1 if "Flash Storage" in x else 0)

df['second'] = df['second'].str.replace(r'\D', '')

df["first"] = df["first"].astype(int)
df["second"] = df["second"].astype(int)

df["HDD"]=(df["first"]*df["Layer1HDD"]+df["second"]*df["Layer2HDD"])
df["SSD"]=(df["first"]*df["Layer1SSD"]+df["second"]*df["Layer2SSD"])
df["Hybrid"]=(df["first"]*df["Layer1Hybrid"]+df["second"]*df["Layer2Hybrid"])
df["Flash_Storage"]=(df["first"]*df["Layer1Flash_Storage"]+df["second"]*df["Layer2Flash_Storage"])

df.drop(columns=['first', 'second', 'Layer1HDD', 'Layer1SSD', 'Layer1Hybrid',
       'Layer1Flash_Storage', 'Layer2HDD', 'Layer2SSD', 'Layer2Hybrid',
       'Layer2Flash_Storage'],inplace=True)

df.sample()

df.corr()['Price']

df.drop(columns=['Hybrid','Flash_Storage'],inplace=True)

df['Gpu brand'] = df['Gpu'].apply(lambda x:x.split()[0])

df.head()

df['Gpu brand'].value_counts()

df=df[df['Gpu brand']!= 'ARM']

df.head()

sns.barplot(x=df['Gpu brand'],y=df['Price'],estimator=np.median)
plt.xticks(rotation='vertical')
plt.show()

df.drop(columns=['Gpu'],inplace=True)

df['OpSys'].value_counts()

sns.barplot(x=df['OpSys'],y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

def cat_os(inp):
    if inp == 'Windows 10' or inp == 'Windows 7' or inp == 'Windows 10 S':
        return 'Windows'
    elif inp == 'macOS' or inp == 'Mac OS X':
        return 'Mac'
    else:
        return 'Others/No OS/Linux'

df['os'] = df['OpSys'].apply(cat_os)

df.drop(columns=['OpSys'],inplace=True)

sns.barplot(x=df['os'],y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

sns.distplot(df['Weight'])

sns.scatterplot(x=df['Weight'],y=df['Price'])

df.corr()['Price']

sns.heatmap(df.corr())

sns.distplot(np.log(df['Price']))

df.to_csv('Laptop_data')

df.head(2)

X = df.drop(columns=['Price','Memory'])

y = np.log(df['Price'])

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.15,random_state=2)

X_train

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import r2_score,mean_absolute_error

from sklearn.linear_model import LinearRegression,Ridge,Lasso
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor,ExtraTreesRegressor
from sklearn.svm import SVR
from xgboost import XGBRegressor

# prompt: ColumnTransformer

step1 = ColumnTransformer([
    ('col_tnf', OneHotEncoder(sparse=False, handle_unknown='ignore'),[0,1,7,10,11])
],remainder='passthrough')

# prompt: Pipeline

step2 = LinearRegression()
pipe = Pipeline([
    ('step1', step1),
    ('step2', step2)
])

pipe.fit(X_train, y_train)
y_pred = pipe.predict(X_test)
# y_pred
# np.exp(y_pred)
# r2_score(y_test, y_pred)
print('R2 score',r2_score(y_test,y_pred))
print('MAE',mean_absolute_error(y_test,y_pred))